<h1>Our Aim</h1>
To build an AI powered real-time sign language translator, to help the deaf and hearing communities talk to each other easily.
<h1>Our Proposal</h1>

<h2>ASSIST - A Dataset for Workplace Communication</h2>  
<div style="text-align: center"><img src="../images/dataset.gif" alt="video dataset example" /></div>
<p style="text-align: center; font-style: italic;"> Example video from our dataset</p>
In order to train state-of-the-art AI models for indian sign language recognition, we first need a large collection of annotated ISL video. We call this dataset <i>ASSIST</i> and target for it to be the largest dataset in any sign language in the world, positioning us favourably to train the most accurate AI models for sign language recognition.

We are currently working with the National Insitute of Speech and Hearing (NISH) to collect this data. Students at NISH enroll for a course on workplace english communication, where we teach them formal english to succeed at the workplace. The students are assigned homework every week, the task being to create sign language videos of english sentences. These videos are submitted and graded, and the correct videos are added to our sign language dataset.

<h2>Build AI models for live sign language recognition on Microsoft Teams </h2>
<div style="text-align: center"><img src="../images/translated_video.gif" alt="translation example" /></div>   
<p style="text-align: center; font-style: italic;"> Processing videos with our AI models</p>
Video conferencing tools, such as Microsoft Teams, have become a primary source of communication for white-collar employees in the post-pandemic reality. To enable seamless real-time conversation between Deaf and able persons, we will build AI models which that can transcribe signed gestures in real-time. Such real-time transcription can significantly reduce barriers to communicate and enable a wider range of people with no exposure to sign language to effectively communicate with deaf people.  

<h2>HCI Research - How can AI models help the DHH community</h2>
We also wish to understand the challenges faced by the DHH community better. In order to do that, we are: <br>
<ul>
<li> Conducting a large formative study amongst the DHH community â€“ both using distributed widely surveys and a smaller number of 1:1 interviews with members of the deaf community </li>
<li> Report on the most important contexts where AI models can meaningfully support the DHH community </li>
<li> Curate a large number of templates of typical multi-turn conversations in the identified contexts </li>
</ul>

<h1>The social impact that we want to create</h1>
As mentioned, India is significantly behind in building capacity for formal education in ISL, in employers having the support systems to hire Deaf people, and in building datasets and AI models to provide the technological support to the DHH community. We aim to change this significantly with impact on the following three axes:

<ol>
<li> Create a network of value-aligned organisations to create data resources at scale in Indian Sign Languages. </li>
<li> Establish scientific leadership in the space of AI technology for sign languages improving on all reported benchmarks of accuracy. </li>
<li> Build a usable, effective, and continuously improving tool for sign language communication on a video calling application (like Microsoft Teams) for the context of workplace communication. </li>
</ol>

<i>All our work is and will always remain in the open-source. </i>
